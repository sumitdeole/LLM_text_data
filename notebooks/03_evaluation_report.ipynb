{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac689ff8",
   "metadata": {},
   "source": [
    "#### Automated Report Generation with Llama 2\n",
    "This report summarizes the performance of our fine-tuned Llama 2 model for SMS spam detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "978627af",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ollama'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mollama\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ollama'"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8233626c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metrics and visualizations\n",
    "metrics = {\n",
    "    'accuracy': 0.954,\n",
    "    'precision': 0.923,\n",
    "    'recall': 0.865,\n",
    "    'f1': 0.893\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805fbf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images as base64 for report\n",
    "def image_to_base64(image_path):\n",
    "    import base64\n",
    "    with open(image_path, \"rb\") as img_file:\n",
    "        return base64.b64encode(img_file.read()).decode('utf-8')\n",
    "\n",
    "conf_matrix_img = image_to_base64('../plots/confusion_matrix.png')\n",
    "metrics_img = image_to_base64('../plots/performance_metrics.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a163294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate report sections using Llama 2\n",
    "def generate_report_section(prompt, temperature=0.3):\n",
    "    response = ollama.generate(\n",
    "        model='llama2',\n",
    "        prompt=textwrap.dedent(prompt),\n",
    "        options={'temperature': temperature}\n",
    "    )\n",
    "    return response['response'].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a446ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Executive Summary\n",
    "exec_summary = generate_report_section(f\"\"\"\n",
    "Create an executive summary for an SMS spam detection model report with these metrics:\n",
    "- Accuracy: {metrics['accuracy']:.1%}\n",
    "- Precision: {metrics['precision']:.1%}  \n",
    "- Recall: {metrics['recall']:.1%}\n",
    "- F1 Score: {metrics['f1']:.1%}\n",
    "\n",
    "Write 3 concise paragraphs highlighting:\n",
    "1. Overall performance\n",
    "2. Business impact\n",
    "3. Key strengths\n",
    "Use professional business language suitable for senior managers.\n",
    "\"\"\")\n",
    "\n",
    "# %%\n",
    "# 2. Methodology\n",
    "methodology = generate_report_section(\"\"\"\n",
    "Describe the methodology used for building an SMS spam classifier with these components:\n",
    "- Llama 2 model via Ollama\n",
    "- Few-shot learning approach\n",
    "- Evaluation on test dataset\n",
    "- Performance metrics calculation\n",
    "\n",
    "Write in academic report style with 3 paragraphs:\n",
    "1. Model selection rationale\n",
    "2. Training approach\n",
    "3. Evaluation protocol\n",
    "\"\"\")\n",
    "\n",
    "# %%\n",
    "# 3. Detailed Analysis\n",
    "analysis = generate_report_section(f\"\"\"\n",
    "Analyze these SMS spam classifier results in detail:\n",
    "\n",
    "Performance Metrics:\n",
    "- Accuracy: {metrics['accuracy']:.1%}\n",
    "- Precision: {metrics['precision']:.1%}\n",
    "- Recall: {metrics['recall']:.1%} \n",
    "- F1: {metrics['f1']:.1%}\n",
    "\n",
    "Confusion Matrix:\n",
    "- True Negatives: 965 (Ham correctly classified)\n",
    "- False Positives: 5 (Ham misclassified as Spam)\n",
    "- False Negatives: 9 (Spam misclassified as Ham)\n",
    "- True Positives: 156 (Spam correctly classified)\n",
    "\n",
    "Write 4 paragraphs covering:\n",
    "1. Metric interpretation\n",
    "2. Error analysis\n",
    "3. Comparison to industry benchmarks\n",
    "4. Limitations\n",
    "\"\"\")\n",
    "\n",
    "# %%\n",
    "# 4. Recommendations\n",
    "recommendations = generate_report_section(\"\"\"\n",
    "Generate strategic recommendations for improving an SMS spam detection system based on these findings:\n",
    "\n",
    "Current performance:\n",
    "- High accuracy but some false negatives\n",
    "- Good precision but recall could improve\n",
    "\n",
    "Provide 5 professional recommendations in bullet points covering:\n",
    "- Model improvements\n",
    "- Data collection\n",
    "- Deployment strategies\n",
    "- Monitoring approaches\n",
    "- Future research directions\n",
    "\"\"\")\n",
    "\n",
    "# %%\n",
    "# Compile the full report\n",
    "report_date = datetime.now().strftime(\"%B %d, %Y\")\n",
    "\n",
    "full_report = f\"\"\"\n",
    "# SMS Spam Detection System Report\n",
    "**Date:** {report_date}  \n",
    "**Author:** Automated Report Generator  \n",
    "**Model:** Llama 2 via Ollama  \n",
    "\n",
    "---\n",
    "\n",
    "## Executive Summary  \n",
    "{exec_summary}\n",
    "\n",
    "---\n",
    "\n",
    "## Methodology  \n",
    "{methodology}\n",
    "\n",
    "---\n",
    "\n",
    "## Results Analysis  \n",
    "![Confusion Matrix](data:image/png;base64,{conf_matrix_img})  \n",
    "![Performance Metrics](data:image/png;base64,{metrics_img})  \n",
    "\n",
    "{analysis}\n",
    "\n",
    "---\n",
    "\n",
    "## Recommendations  \n",
    "{recommendations}\n",
    "\n",
    "---\n",
    "\n",
    "### Appendix  \n",
    "- Test dataset size: {len(test_df)} messages\n",
    "- Training approach: Few-shot learning\n",
    "- Model version: llama2 (7B parameters)\n",
    "- Report generated automatically\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "# Save report\n",
    "with open('../automated_report.md', 'w', encoding='utf-8') as f:\n",
    "    f.write(full_report)\n",
    "\n",
    "# Convert to PDF\n",
    "try:\n",
    "    from md2pdf.core import md2pdf\n",
    "    md2pdf(\n",
    "        \"../automated_report.pdf\",\n",
    "        md_content=full_report,\n",
    "        base_url=None\n",
    "    )\n",
    "    print(\"PDF report generated successfully!\")\n",
    "except ImportError:\n",
    "    print(\"Markdown report saved. Install md2pdf for PDF conversion.\")\n",
    "\n",
    "# %%\n",
    "# Display report sections\n",
    "from IPython.display import display, Markdown\n",
    "display(Markdown(full_report))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
