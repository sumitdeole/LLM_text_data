{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6e1f113",
   "metadata": {},
   "source": [
    "#### SMS Spam Collection - Mistral Embeddings with Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e76ba9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "import concurrent.futures\n",
    "import ollama\n",
    "\n",
    "os.makedirs(\"../data\", exist_ok=True)\n",
    "os.makedirs(\"../plots\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a941dd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('../data/spam.csv', encoding='latin-1')\n",
    "df['label'] = df['v1'].map({'ham': 0, 'spam': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25e3aadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sumit\\AppData\\Local\\Temp\\ipykernel_19848\\2491015376.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_sample = df.groupby('label').apply(lambda x: x.sample(n=min(1000, len(x)), random_state=42)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# Split data and generate sample\n",
    "df_sample = df.groupby('label').apply(lambda x: x.sample(n=min(1000, len(x)), random_state=42)).reset_index(drop=True)\n",
    "\n",
    "texts = df_sample['v2'].values\n",
    "labels = df_sample['label'].values\n",
    "texts_train, texts_test, y_train, y_test = train_test_split(\n",
    "    texts, labels, test_size=0.3, stratify=labels, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c8ae6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings with Mistral (sampled)...\n"
     ]
    }
   ],
   "source": [
    "# Embedding function\n",
    "def get_embedding(text):\n",
    "    try:\n",
    "        return ollama.embeddings(model='mistral', prompt=text[:512])['embedding']\n",
    "    except:\n",
    "        return [0.0] * 4096\n",
    "    \n",
    "# Parallel embedding\n",
    "print(\"Generating embeddings with Mistral (sampled)...\")\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    X_train = np.array(list(executor.map(get_embedding, texts_train)))\n",
    "    X_test = np.array(list(executor.map(get_embedding, texts_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c103527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97       301\n",
      "           1       1.00      0.93      0.96       224\n",
      "\n",
      "    accuracy                           0.97       525\n",
      "   macro avg       0.97      0.96      0.97       525\n",
      "weighted avg       0.97      0.97      0.97       525\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "clf = RandomForestClassifier(n_estimators=100, class_weight='balanced')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27eab09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics for later report use\n",
    "metrics_df = pd.DataFrame([{\n",
    "    'accuracy': report['accuracy'],\n",
    "    'precision': report['1']['precision'],\n",
    "    'recall': report['1']['recall'],\n",
    "    'f1': report['1']['f1-score']\n",
    "}])\n",
    "metrics_df.to_csv('../data/model_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a38fed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Legitimate', 'Fraud'],\n",
    "            yticklabels=['Legitimate', 'Fraud'])\n",
    "plt.title('Fraud Detection Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../plots/confusion_matrix.png', dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dd93668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIME Explanations\n",
    "explainer = LimeTextExplainer(class_names=['ham', 'spam'])\n",
    "\n",
    "def predict_proba(texts):\n",
    "    emb = np.array([get_embedding(t) for t in texts])\n",
    "    return clf.predict_proba(emb)\n",
    "\n",
    "fraud_indices = np.where(y_test == 1)[0]\n",
    "if len(fraud_indices) > 0:\n",
    "    idx = fraud_indices[0]\n",
    "    exp = explainer.explain_instance(\n",
    "        text_instance=texts_test[idx],\n",
    "        classifier_fn=predict_proba,\n",
    "        num_features=10,\n",
    "        num_samples=300\n",
    "    )\n",
    "    exp.save_to_file('../plots/lime_explanation.html')\n",
    "    fig = exp.as_pyplot_figure()\n",
    "    fig.set_size_inches(10, 6)\n",
    "    plt.title('LIME Explanation for Fraud Prediction')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../plots/lime_visualization.png', dpi=300)\n",
    "    plt.close()\n",
    "else:\n",
    "    print(\"No fraud samples in test set to explain.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
